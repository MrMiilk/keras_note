{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型API\n",
    "- 查阅时应该找文档，这个只是为了减慢阅读速度的笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential模型和函数式模型的通用API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()#打印模型的概况\n",
    "model.get_config()#返回包含模型配置信息的Python字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#模型也可以从它的config信息中重构回去\n",
    "config = model.get_config()\n",
    "model = Model.from_config(config)\n",
    "#sequential独有：\n",
    "model = Sequential.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.get_layer() #根据层名或下标获得层对象\n",
    "model.det_weights()  #模型权重列表，类型为np.ndarray\n",
    "model.set_weights()  #从np.ndarray中载入权重--形状匹配\n",
    "model.to_json()      #返回代表模型的JSON字符串，仅包含网络结构，不包含权值。\n",
    "model.to_yaml()       #和json类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#可以从JSON字符串中重构原模型：\n",
    "from models import model_from_json\n",
    "\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "#yaml也是一样的\n",
    "from models import model_from_yaml\n",
    "\n",
    "yaml_string = model.to_yaml()\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(filepath) #保存权重文件，类型是HDF5(.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从HDF5文件中加载权重到当前模型中, 默认情况下模型的结构将保持不变。\n",
    "如果想将权重载入不同的模型（有些层相同）中，则设置by_name=True，\n",
    "只有名字匹配的层才会载入权重\n",
    "\"\"\"\n",
    "model.load_weights(filepath, by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential模型API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers  #获得模型中层的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数式模型\n",
    "- [Link](http://keras-cn.readthedocs.io/en/latest/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "a = Input(shape=(32,))\n",
    "b = Dense(32)(a)\n",
    "model = Model(inputs=a, outputs=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.topology.InputLayer object at 0x000001C94C9CA710>, <keras.layers.core.Dense object at 0x000001C94C9CA4E0>]\n",
      "[<tf.Tensor 'input_1:0' shape=(?, 32) dtype=float32>]\n",
      "[<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 32) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)\n",
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [compile]()：编译模型以提供训练，只是predict的话，不需要\n",
    "- 总体：\n",
    "```python\n",
    "compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "```\n",
    "- 常见参数：\n",
    "    - optimozer\n",
    "    - loss\n",
    "    - metrics 评估指标列表\n",
    "        - 如果要在多输出模型中为**不同的输出指定不同的指标**，可像该参数传递一个字典，例如metrics={'ouput_a': 'accuracy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [fit]()：训练模型\n",
    "- 总体：\n",
    "```python\n",
    "fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "```\n",
    "- 常见参数：\n",
    "    - X\n",
    "    - y\n",
    "    - batch_size\n",
    "    - epochs\n",
    "    - verbose:日志\n",
    "        - 0：不输出\n",
    "        - 1：输出进度记录条\n",
    "        - 2：输出每个epoch的记录--其他函数大多只能取0/1\n",
    "    - validation_split:0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。\n",
    "        - 注意，validation_split的划分在shuffle之后，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。\n",
    "    - validation_data:(X, y),会覆盖validation_split\n",
    "    - shuffle:**每个epoch**前随机打乱输入样本的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### [evalute]():按batch计算给定数据的模型误差\n",
    "- 总体：\n",
    "```python\n",
    "evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)\n",
    "```\n",
    "- 参数：\n",
    "    - X\n",
    "    - Y\n",
    "    - batch_size:\n",
    "    - ver_bose:只能取0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [predict]():\n",
    "- 返回的类型是ndarray\n",
    "```python\n",
    "predict(self, x, batch_size=32, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [xx_on_batch]()\n",
    "- train/test/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以直接使用自己定义的函数名，或者是Tensorflow的符号函数\n",
    "- 常用的目标函数：\n",
    "```python\n",
    "from keras import losses\n",
    "loss = losses.xxx\n",
    "```\n",
    "    - mean_squared_error\n",
    "    - mean_absolute_error\n",
    "    - squared_hinge\n",
    "    - categorical_crossentropy\n",
    "    ...\n",
    "- **注意：**在使用categorical_crossentropy作为损失函数时，对应类别应该为多类别，label应该使用one_hot编码，可以使用to_categorical直接转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keraas import optimzers\n",
    "\n",
    "sgd = optimzers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimzer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 梯度剪裁\n",
    "```python\n",
    "from keras import optimizers\n",
    "\n",
    "#All parameters gradients will be clipped to\n",
    "#a maximun of 1.\n",
    "sgd = optimzers.SGD(lr=0.001, clipnorm=1.)\n",
    "\n",
    "#...\n",
    "# a maximum value of 0.5 and\n",
    "# a minimum value of -0.5.\n",
    "sgd = optimzer.SGD(lr=0.1, clipvalue=0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用optimzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF优化器的包装器\n",
    "```python\n",
    "keras.optimizers.TFOptimizer(optimizer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD\n",
    "```python\n",
    "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "```\n",
    "- 参数\n",
    "    - lr：\n",
    "    - momentum\n",
    "    - decay\n",
    "    - nesterov:True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSprop\n",
    "```python\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "```\n",
    "- 参数\n",
    "    - lr\n",
    "    - rho\n",
    "    - epsilon：防止除0的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad\n",
    "```python\n",
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目前没用过的 Adadelte\n",
    "```python\n",
    "keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam\n",
    "```python\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adamax\n",
    "- Adam的变体--在Adam论文里\n",
    "```python\n",
    "keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadam\n",
    "- Nesterov Adam optimizer: Adam本质上像是带有动量项的RMSprop，Nadam就是带有Nesterov 动量的Adam RMSprop\n",
    "```python\n",
    "keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数\n",
    "- 可以单独设置激活层或者在构造层的时候加入，或者用TF的函数\n",
    "```python\n",
    "#Activation层\n",
    "keras.layers.core.Activation(activation)\n",
    "```\n",
    "- 预定义的激活函数(知道的)\n",
    "    - softplus\n",
    "    - relu\n",
    "    - softmax\n",
    "    - tanh\n",
    "- 高级激活函数\n",
    "    - LeaktReLU:避免ReLU可能出现的失活现象\n",
    "```python\n",
    "keras.layers.advanced_activations.LeakyReLU(alpha=0.3)\n",
    "```\n",
    "    - PReLU:参数化的ReLU,alpha可学习\n",
    "```python\n",
    "keras.layers.advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n",
    "```\n",
    "        - 参数：\n",
    "            - alpha_constraint:**约束项？？**\n",
    "            - shared_axes:共享参数的轴，比如输入tensor为`(batch_size,height,width,channels)`,如果希望每个filter都用相同的参数，只需要设置 `hared_axes=[1, 2]`\n",
    "    - ELU层：指数线性单元\n",
    "    ```python\n",
    "    keras.layers.advanced_activations.ELU(alpha=1.0)\n",
    "    ```\n",
    "        - 表达式\n",
    "```python\n",
    "f(x) = alpha * (exp(x) - 1.) for x < 0, f(x) = x for x>=0\n",
    "```\n",
    "    - ThresholdedReLU层\n",
    "    ```python\n",
    "    keras.layers.advanced_activations.ThresholdedReLU(theta=1.0)\n",
    "    ```\n",
    "        - 表达式\n",
    "        ```ptrhon\n",
    "        f(x) = x for x > theta,f(x) = 0 otherwise\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#使用TF自带的函数作为激活函数\n",
    "def tanh(x):\n",
    "    return K.tanh(x)\n",
    "\n",
    "X = Dense(64, activation=tanh)(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在上面有提过，模型编译时，通过metrics进行设置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mae', 'acc'])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=[metrics.mae, metrics.categorical_accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 自定义函数\n",
    "- 输入\n",
    "    > y_true  \n",
    "     y_pred\n",
    "- 返回\n",
    "    > 返回单个张量,或从`metric_name`映射到`metric_value`的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mean_err(y_true, y_pred):\n",
    "    return K.mean(y_pred -  y_true)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['mean_err', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化方法\n",
    "- 正常对应设置中的`kernel_initializer`或者`bias_initializer`\n",
    "- 使用对应初始化方法的字符串或者函数名\n",
    "- 自定义估计目前没啥用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializer类\n",
    "- Initializer是所有初始化方法的父类，不能直接使用，如果想要定义自己的初始化方法，需要继承此类\n",
    "- 常见方法：\n",
    "```python\n",
    "keras.initializers.Ones()\n",
    "keras.initializers.Zeros()\n",
    "keras.initializers.Constant(value=0)\n",
    "#正态分布\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None))\n",
    "#均匀分布\n",
    "keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "#截尾正态分布:位于均值两边两个stddev外的数据会直接重新生成\n",
    "keras.initializers.TruncatedNormal(mean=.0, stddev=0.005, seed=None)\n",
    "#xavier初始化\n",
    "'''\n",
    "参数从[-limit, limit]范围内的均匀分布产生，limit=sqrt(6/fan_in+fan_out),fan_in,fan_out分别是输入，输出的权重张量的单元数\n",
    "'''\n",
    "keras.initializers.glorot_uniform(seed=None)\n",
    "#...还有很多初始化方法\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 正则项\n",
    "- [原码](https://github.com/keras-team/keras/blob/master/keras/regularizers.py·)\n",
    "- 在层定义的时候添加的项-->会作为损失函数的一部分进行优化\n",
    "- 都是keras.regularizer.Regularizer对象，在层中添加的参数\n",
    "    - `kernel_regularizer`:权重惩罚\n",
    "    - `bias_regularizer`：偏置惩罚\n",
    "    - `activity_regulaizer`:输出的惩罚\n",
    "- 可用的正则项\n",
    "    ```python\n",
    "    keras.regularizers.l1(0.)  \n",
    "    keras.regularizers.l2(0.)  \n",
    "    keras.regularizers.l1_l2(l1=0., l2=0.)  \n",
    "    ```\n",
    "- 自定义的正则项\n",
    "```python\n",
    "    from keras import backend as K\n",
    "\n",
    "    def l1_reg(weight_matrix):\n",
    "        return 0.01*K.sum(K.abs(weight_matrix))\n",
    "    X = Dense(64, input_dim=64, kernel_regularizer=l1_reg)(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 约束项\n",
    "- 在constraints模块中\n",
    "- 构造中常见的参数\n",
    "     - kernel_constraint\n",
    "     - bias_constraint\n",
    "- 预定义的约束项\n",
    "     - max_norm(m=2)：模值约束\n",
    "     - non_neg()：非负约束\n",
    "     - unit_norm()：**？？单位范数约束，强制矩阵沿最后一个轴拥有单位范数**\n",
    "     - min_max_norm(min_value=0., max_value=1., rate=1., axix=0):最大最小范数约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.Constrains import maxnorm\n",
    "\n",
    "X = Dense(64, kernel_constraint=max_norm(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回调函数Callbacks\n",
    "- 在训练的特定阶段被调用的函数集，可以比如用于观察训练中网络内部的变量观察这类的(Tensorboard之类的)\n",
    "- 一个类--`keras.callbacks.Callback`，定义新的回调函数需要继承这个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#例子:记录损失函数的历史数据\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "X_i = Input(input_shape)\n",
    "X = Dense(10, input_dim=784, kernel_initializer='uniform')(X_i)\n",
    "Y = Activation('softmax')(X)\n",
    "model = Model(inputs=X_i, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimzer='rmsprop')\n",
    "history = LossHistory()\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, callbacks=[history])\n",
    "print(history.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 回调函数以logs为字典，在训练的不同阶段会记录不同的数据\n",
    "- on_epoch_end:`log={acc, loss}`，如果指定了验证集，还会包含`val_acc和val_loss`,**注意这里要求compile中`metrics`指定`accuracy`**\n",
    "- on_batch_begin:`size`，当前batch的样本数\n",
    "- on_batch_end:`logs={loss, (acc)}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 几个常用的callback函数  \n",
    "1. 在每个epoch后面保存模型到`filepath`\n",
    "```python\n",
    "keras.callbacks.ModelCheckpoint(  \n",
    "    filepath,monitor='val_loss',  \n",
    "    verbose=0, save_best_only=False,save_weights_only=False,  \n",
    "    mode='auto', period=1)```\n",
    "    - 这里`filepath`可以是格式化的字符串，里面的占位符会被`epoch`和传入`on_epoch_end`的`logs`的关键字替代，比如 \n",
    "```python\n",
    "# 生成对应epoch和loss的文件\n",
    "filepath = 'weights.{epoch:02d-{val_loss:.3f}}.hdf5'\n",
    "```\n",
    "    - `monitor`为需要监视的变量名\n",
    "    - `save_best_only`:为`True`时，只保存在验证集上性能最好的模型\n",
    "    - `mode`:在`save_best_only=True`时决定性能最佳模型的评判准则，例如，当监测值为`val_acc`时，模式应为`max`，当检测值为`val_loss`时，模式应为`min`,在`auto`模式下，评价准则由被监测值的名字自动推断\n",
    "    - `save_weight_only`:`False`时将保存模型结构，配置信息等\n",
    "    - `period`:间隔几个`epoch`执行一次  \n",
    "2. 早停策略\n",
    "```python\n",
    "keras.callbacks.EarlyStopping(  \n",
    "    monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "```\n",
    "    - `monitor`:需要监视的量\n",
    "    - `patience`:当early stop被激活，则经过patience个epoch后停止训练\n",
    "    - 'mode':‘auto’，‘min’，‘max’之一，在`min`模式下，如果检测值停止下降则中止训练。在`max`模式下，当检测值不再上升则停止训练\n",
    "- 可视化的`Tensorboard`\n",
    "```python\n",
    "keras.callbacks.TensorBoard(  \n",
    "    log_dir='./logs', histogram_freq=0,  \n",
    "    write_graph=True,write_images=False, embeddings_freq=0,   \n",
    "    embeddings_layer_names=None, embeddings_metadata=None)\n",
    "```\n",
    "    - `log_dir`:保存日志文件的地址\n",
    "    - `histogram_freq`:多少个epoch计算一次\n",
    "3. 创建简单的callback类\n",
    "```python\n",
    "keras.callbacks.LambdaCallback(  \n",
    "    on_epoch_begin=None, on_epoch_end=None,  \n",
    "    on_batch_begin=None, on_batch_end=None,  \n",
    "    on_train_begin=None, on_train_end=None)\n",
    "```\n",
    "    - 匿名函数的参数：\n",
    "        - `on_epoch_begin`,`on_epoch_end`:假定输入是`eppoch`，`logs`\n",
    "        - `on_batch_begin`,`on_batch_end`:假定输入时`batch`，`logs`\n",
    "        - `on_train_begin`,`on_train_end`:假定输入时`logs`\n",
    "    - 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印batch number\n",
    "batch_print_callback = LambdaCallback(\n",
    "    on_batch_begin=lambda: batch, logs:print(batch))\n",
    "\n",
    "#画出loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_loss_callback = LambdeCallback(\n",
    "    on_epoch_end=lambda epoch, logs:plt.plot(np.arange(epoch), \n",
    "                                             logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "'''\n",
    "saves the model weights after each epoch if the validation loss decreased\n",
    "'''\n",
    "checkpointer = ModelCheckpoint(filepath=\"/tmp/weights.hdf5\", verbose=1, save_best_only=True)\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预训练模型\n",
    "> 提供常见的图像分类模型  \n",
    " [权重文件](https://pan.baidu.com/s/1geHmOpH#list/path=%2F&parentPath=%2F)\n",
    "![](images/keras_nets.png)\n",
    "< 下面给一些迁移学习的例子，keras提供的模型可以直接在文档查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50做分类\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprossing import image\n",
    "from keras.applications.resnet50 import prepross_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "img_path = 'xx.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)#batch轴\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict()\n",
    "classes, description, probabiity = decode_predictions(preds, top=3)\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (\n",
    "#u'n01871265', u'tusker', 0.1122357), \n",
    "#(u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16特征提取\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "img_path = 'xx.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-19提取中间层特征\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在新的类别上fine_tune inceptionV3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)#不需要顶层\n",
    "x = base_model.output\n",
    "#添加需要的层\n",
    "x = GlobalAveragePooling2D()(X)\n",
    "perd = Dense(200, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=pred)\n",
    "#原模型不再训练,先训练最后两层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(opptimizer='sgd', loss='categorical_crossentropy')\n",
    "model.fit_generator(...)\n",
    "#fine_tune模型，依旧选择需要的层，设置trainable\n",
    "for i,layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum0.9), loss='categorical_crossentropy')\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建新的输入的InceptionV3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用数据集\n",
    "```python\n",
    "from keras.datasets import ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化模型\n",
    "- 个人还是喜欢tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "'''\n",
    "参数：\n",
    "    show_shapes:显示输出数据的形状，默认False\n",
    "    show_layer_names:是否显示层名称\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在ipython显示\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "#依赖 pydot-ng 和 graphviz\n",
    "#pip install pydot-ng & brew install graphviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
